# -*- coding: utf-8 -*-
"""Text_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-jb2PEpQaEKAasqcb5nmTQTeFm03luAl
"""
import streamlit as st
import pandas as pd
from textblob import TextBlob
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from nltk import ne_chunk, pos_tag, word_tokenize
from nltk.tree import Tree
import nltk

# Download NLTK resources
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

# Function to perform sentiment analysis using TextBlob
def analyze_sentiment(text):
    blob = TextBlob(text)
    sentiment_score = blob.sentiment.polarity
    if sentiment_score > 0:
        return "Positive"
    elif sentiment_score < 0:
        return "Negative"
    else:
        return "Neutral"

# Function to perform named entity recognition using NLTK
def analyze_named_entities(text):
    entities = []
    for chunk in ne_chunk(pos_tag(word_tokenize(text))):
        if isinstance(chunk, Tree):
            entities.append(" ".join([token for token, pos in chunk.leaves()]))
    return entities

# Streamlit app
def main():
    st.set_page_config(
        page_title="Text Analytics",
        layout="wide",
        initial_sidebar_state="expanded",
        page_icon=":memo:",
    )
    st.title("Text Analytics")
    
    # Upload CSV
    uploaded_file = st.file_uploader("Upload CSV file", type=["csv"])
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        # Filter out only text columns
        text_columns = [col for col in df.columns if df[col].dtype == 'object']
        df = df[text_columns].drop(columns=['unnamed', 'rows'], errors='ignore')

        # Display uploaded data
        st.write(df)
    
        # Perform text analytics based on selected options
        if st.button("Perform Text Analytics"):
            for col in text_columns:
                st.subheader(f"Text Analytics for Column: {col}")
                # Sentiment analysis
                st.subheader("Sentiment Analysis Results")
                df[f'{col}_Sentiment'] = df[col].apply(analyze_sentiment)
                st.write(df[[col, f'{col}_Sentiment']])

                # Named entity recognition
                st.subheader("Named Entity Recognition Results")
                df[f'{col}_Entities'] = df[col].apply(analyze_named_entities)
                st.write(df[[col, f'{col}_Entities']])

    # Visualizations
    st.sidebar.title("Visualizations")
    if st.sidebar.checkbox("Show Histogram"):
        st.subheader("Histogram")
        if 'text' in df.columns:
            text_column = st.sidebar.selectbox("Select column for histogram:", df.columns)
            fig, ax = plt.subplots(figsize=(8, 6))  # Set a smaller figure size
            df[text_column].hist(ax=ax)  # Plot the histogram on the axes
            st.pyplot(fig)  # Display the figure using st.pyplot()
        else:
            st.warning("No data to display.")
    
    if st.sidebar.checkbox("Show Word Cloud"):
        st.subheader("Word Cloud")
        if 'text' in df.columns:
            text = ' '.join(df['text'])
            wordcloud = WordCloud().generate(text)
            fig, ax = plt.subplots(figsize=(8, 6))  # Set a smaller figure size
            ax.imshow(wordcloud, interpolation='bilinear')
            ax.axis("off")
            st.pyplot(fig)  # Display the figure using st.pyplot()
        else:
            st.warning("No data to display.")

if __name__ == "__main__":
    main()
