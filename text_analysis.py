# -*- coding: utf-8 -*-
"""Text_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-jb2PEpQaEKAasqcb5nmTQTeFm03luAl
"""
import streamlit as st
import pandas as pd
import nltk
from nltk import word_tokenize
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from textblob import TextBlob

# Download NLTK resources
nltk.download('punkt')

# Function to perform Sentiment Analysis
def analyze_sentiment(text):
    blob = TextBlob(text)
    sentiment_score = blob.sentiment.polarity
    if sentiment_score > 0:
        return 'Positive'
    elif sentiment_score < 0:
        return 'Negative'
    else:
        return 'Neutral'

# Function to generate Word Cloud for positive sentiment words
def generate_positive_wordcloud(text):
    positive_words = ' '.join([word for word in word_tokenize(text) if analyze_sentiment(word) == 'Positive'])
    wordcloud = WordCloud(width=800, height=400, background_color ='white').generate(positive_words)
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    st.pyplot(fig)

# Function to generate Word Cloud for negative sentiment words
def generate_negative_wordcloud(text):
    negative_words = ' '.join([word for word in word_tokenize(text) if analyze_sentiment(word) == 'Negative'])
    wordcloud = WordCloud(width=800, height=400, background_color ='white').generate(negative_words)
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    st.pyplot(fig)

# Main function
def main():
    st.title("Text Analysis App")

    # Option to upload a CSV file for sentiment analysis
    uploaded_file = st.file_uploader("Upload CSV file for sentiment analysis:", type=["csv"])
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)

        # Slider to select the number of rows to analyze
        chunk_size = st.slider("Select chunk size:", min_value=50, max_value=len(df), value=100)

        # Analyze data in chunks
        for i in range(0, len(df), chunk_size):
            st.write(f"Analyzing rows {i+1}-{min(i+chunk_size, len(df))}")

            # Get text data for current chunk
            text = ' '.join(df.iloc[i:min(i+chunk_size, len(df))][text_column].dropna())

            # Analyze sentiment
            sentiment = analyze_sentiment(text)
            st.write("Sentiment:", sentiment)

            # Generate Word Cloud for positive sentiment words
            st.write("Positive Sentiment Word Cloud:")
            generate_positive_wordcloud(text)

            # Generate Word Cloud for negative sentiment words
            st.write("Negative Sentiment Word Cloud:")
            generate_negative_wordcloud(text)

if __name__ == "__main__":
    main()
